{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['sample']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.672175</td>\n",
       "      <td>0.184493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042170</td>\n",
       "      <td>0.496807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036909</td>\n",
       "      <td>0.231968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.185166</td>\n",
       "      <td>-0.163244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199091</td>\n",
       "      <td>-0.207021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.262389</td>\n",
       "      <td>0.446881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.619550</td>\n",
       "      <td>0.039807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.441863</td>\n",
       "      <td>-0.003950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.280229</td>\n",
       "      <td>-0.352572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.074489</td>\n",
       "      <td>-0.497364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.642289</td>\n",
       "      <td>-0.003541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.039664</td>\n",
       "      <td>0.348849</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.482525</td>\n",
       "      <td>0.559799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.124801</td>\n",
       "      <td>0.363961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.458646</td>\n",
       "      <td>0.503909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.495335</td>\n",
       "      <td>0.298197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.210670</td>\n",
       "      <td>-0.264776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.165189</td>\n",
       "      <td>0.312122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.230463</td>\n",
       "      <td>-0.013246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.828194</td>\n",
       "      <td>-0.483710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.785869</td>\n",
       "      <td>-0.236199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.710011</td>\n",
       "      <td>0.414047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.466424</td>\n",
       "      <td>0.761995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.457970</td>\n",
       "      <td>0.661598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.598318</td>\n",
       "      <td>-0.822166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.822132</td>\n",
       "      <td>-0.157712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.495373</td>\n",
       "      <td>-0.771143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.742236</td>\n",
       "      <td>0.718222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.637788</td>\n",
       "      <td>0.566488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.930616</td>\n",
       "      <td>0.403671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.822037</td>\n",
       "      <td>0.690998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.848675</td>\n",
       "      <td>0.638044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.632603</td>\n",
       "      <td>-0.566063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.798888</td>\n",
       "      <td>-0.797275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.866567</td>\n",
       "      <td>0.090772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.829719</td>\n",
       "      <td>-0.199496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.788110</td>\n",
       "      <td>0.531920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.696535</td>\n",
       "      <td>0.034561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.584470</td>\n",
       "      <td>0.828778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2  target\n",
       "0   0.672175  0.184493       1\n",
       "1  -0.042170  0.496807       1\n",
       "2   0.036909  0.231968       1\n",
       "3  -0.185166 -0.163244       1\n",
       "4   0.199091 -0.207021       1\n",
       "5  -0.262389  0.446881       1\n",
       "6   0.619550  0.039807       1\n",
       "7   0.441863 -0.003950       1\n",
       "8   0.280229 -0.352572       1\n",
       "9   0.074489 -0.497364       1\n",
       "10  0.642289 -0.003541       1\n",
       "11  0.039664  0.348849       1\n",
       "12  0.482525  0.559799       1\n",
       "13 -0.124801  0.363961       1\n",
       "14  0.458646  0.503909       1\n",
       "15  0.495335  0.298197       1\n",
       "16  0.210670 -0.264776       1\n",
       "17 -0.165189  0.312122       1\n",
       "18  0.230463 -0.013246       1\n",
       "19  0.828194 -0.483710       0\n",
       "20 -0.785869 -0.236199       0\n",
       "21 -0.710011  0.414047       0\n",
       "22 -0.466424  0.761995       0\n",
       "23 -0.457970  0.661598       0\n",
       "24  0.598318 -0.822166       0\n",
       "25  0.822132 -0.157712       0\n",
       "26 -0.495373 -0.771143       0\n",
       "27 -0.742236  0.718222       0\n",
       "28 -0.637788  0.566488       0\n",
       "29 -0.930616  0.403671       0\n",
       "30 -0.822037  0.690998       0\n",
       "31  0.848675  0.638044       0\n",
       "32 -0.632603 -0.566063       0\n",
       "33 -0.798888 -0.797275       0\n",
       "34  0.866567  0.090772       0\n",
       "35  0.829719 -0.199496       0\n",
       "36 -0.788110  0.531920       0\n",
       "37 -0.696535  0.034561       0\n",
       "38 -0.584470  0.828778       0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a frame\n",
    "with open('train_02.json') as config:\n",
    "    conf_data = json.load(config)\n",
    "    frame_inside = DataFrame.from_dict(conf_data['inside'])\n",
    "    frame_outside = DataFrame.from_dict(conf_data['outside'])\n",
    "frame_inside['target'] = 1\n",
    "frame_outside['target'] = 0\n",
    "frame = frame_inside.append(frame_outside, ignore_index=True)\n",
    "frame.rename(columns = {0: 'x1', 1: 'x2'}, inplace = True)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.67217518,  0.18449311],\n",
       "       [-0.04216992,  0.49680717],\n",
       "       [ 0.03690877,  0.23196814],\n",
       "       [-0.18516647, -0.16324435],\n",
       "       [ 0.19909138, -0.20702094],\n",
       "       [-0.26238944,  0.446881  ],\n",
       "       [ 0.61955036,  0.03980698],\n",
       "       [ 0.44186287, -0.00394976],\n",
       "       [ 0.28022869, -0.3525718 ],\n",
       "       [ 0.07448928, -0.49736449],\n",
       "       [ 0.64228882, -0.0035411 ],\n",
       "       [ 0.03966422,  0.34884887],\n",
       "       [ 0.48252518,  0.55979929],\n",
       "       [-0.12480142,  0.36396073],\n",
       "       [ 0.45864564,  0.50390885],\n",
       "       [ 0.4953345 ,  0.29819698],\n",
       "       [ 0.21067006, -0.26477567],\n",
       "       [-0.16518915,  0.31212217],\n",
       "       [ 0.23046293, -0.01324642],\n",
       "       [ 0.82819376, -0.48370952],\n",
       "       [-0.78586935, -0.23619862],\n",
       "       [-0.71001137,  0.41404673],\n",
       "       [-0.4664239 ,  0.76199526],\n",
       "       [-0.45796968,  0.66159824],\n",
       "       [ 0.59831813, -0.82216557],\n",
       "       [ 0.82213203, -0.15771201],\n",
       "       [-0.49537312, -0.77114267],\n",
       "       [-0.7422365 ,  0.71822248],\n",
       "       [-0.63778798,  0.5664881 ],\n",
       "       [-0.93061633,  0.4036711 ],\n",
       "       [-0.82203738,  0.69099775],\n",
       "       [ 0.84867531,  0.63804444],\n",
       "       [-0.63260258, -0.56606313],\n",
       "       [-0.7988879 , -0.79727471],\n",
       "       [ 0.86656727,  0.09077183],\n",
       "       [ 0.82971871, -0.19949615],\n",
       "       [-0.78810993,  0.53191962],\n",
       "       [-0.69653453,  0.03456075],\n",
       "       [-0.58446951,  0.82877819]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = frame.iloc[:,0:-1].to_numpy()\n",
    "targets = frame.iloc[:,-1].to_numpy()\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(sample, targets, test_size = 0.4, random_state = 1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = lambda x: ((1 - np.sign(x))/2).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def make_expanded_vector(self, vector, dim):\n",
    "        \"\"\" Function define support vector for correction no positive defined matrix\n",
    "            :params vector, dim: sample vector,  vector dimention\n",
    "            :return: expanded vector of sample vector\n",
    "            \n",
    "        >>> a.make_expanded_vector([0.602314  , 0.48909991], 2)\n",
    "        array([0.36278215, 0.29459172, 0.29459172, 0.23921872, 0.602314  ,\n",
    "            0.48909991, 1.])\n",
    "       \n",
    "        >>> a.make_expanded_vector([0.602314  , 0.48909991, 0.3445601], 3)\n",
    "        array([0.36278215, 0.29459172, 0.20753337, 0.29459172, 0.23921872,\n",
    "            0.16852431, 0.20753337, 0.16852431, 0.11872166, 0.602314  ,\n",
    "            0.48909991, 0.3445601 , 1.        ])\n",
    "        \"\"\"\n",
    "        ksi = np.einsum('i,j->ij', vector, vector).ravel()\n",
    "        for vector_index in range(dim):    \n",
    "            ksi = np.append(ksi, vector[vector_index])\n",
    "        ksi = np.append(ksi, 1)\n",
    "        return ksi\n",
    "    \n",
    "    def make_support_vector(self, list_, dim):\n",
    "        \"\"\" Function define support vector for correction no positive defined matrix\n",
    "            :params list_, dim: vector, vector dimention\n",
    "            :return: support vector\n",
    "            \n",
    "        >>> a.make_support_vector([0.602314  , 0.48909991, 0.3445601], 3)\n",
    "        array([0.36278215, 0.29459172, 0.20753337, 0.29459172, 0.23921872,\n",
    "            0.16852431, 0.20753337, 0.16852431, 0.11872166, 0.        ,\n",
    "            0.        , 0.        , 0.        ])\n",
    "       \n",
    "        >>> a.make_support_vector([0.602314] , 1)\n",
    "        array([0.36278215, 0.        , 0.        ])\n",
    "        \"\"\"\n",
    "        support_vector = np.einsum('i,j->ij',list_,list_).ravel()\n",
    "        for j in range(dim + 1):    \n",
    "            support_vector = np.append(support_vector, 0)\n",
    "        return support_vector\n",
    "        \n",
    "    def check_positive_defined_matrix(self, dim):\n",
    "        \"\"\" Function define and correct no positive defined matrix\n",
    "            :params dim: train set dimention \n",
    "            :return: none\n",
    "        \"\"\"\n",
    "        A = self.alpha[:dim**2]\n",
    "        matrix = A.reshape(dim, dim)\n",
    "        eigen_values, eigen_vectors = linalg.eigh(matrix)\n",
    "        #find negative eigenvalues of atrix\n",
    "        negative_eigenval = list(filter(lambda x: np.any(x <= 0), eigen_values))\n",
    "        if (list(filter(lambda x: np.any(x <= 0), eigen_values))):\n",
    "            negative_eigenval_index = list(eigen_values)\\\n",
    "            .index(list(filter(lambda x: np.any(x <= 0), eigen_values)))\n",
    "            etta = self.make_support_vector(eigen_vectors[negative_eigenval_index], dim)\n",
    "            self.alpha += etta\n",
    "    \n",
    "\n",
    "           \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Function evaluate \n",
    "            :params X: sample vectors\n",
    "            :return: evaluated values for X\n",
    "            \n",
    "        >>> a.predict(np.array([[0.82650592, 0.94031581]]))\n",
    "        array([1])\n",
    "    \n",
    "        >>> a.predict(np.array([[0.68506255, 0.0115562 ]]))\n",
    "        array([0])\n",
    "        \"\"\"\n",
    "        ksi = [0] * len(X)\n",
    "        dim = X.shape[1]\n",
    "        for k in range(X.shape[0]):\n",
    "            ksi[k] =  self.make_expanded_vector(X[k], dim)\n",
    "        ksi = numpy.array(ksi)\n",
    "        return distribution(ksi.dot(self.alpha))\n",
    "\n",
    "    def fit(self, X, target):\n",
    "        \"\"\" Function fits the model\n",
    "            :params X, target: sample values, target values for X\n",
    "            :return: fited model\n",
    "            \n",
    "        a=Perceptron()\n",
    "        >>>a.fit(np.array([[0.72952007, 0.72863373],\n",
    "                   [0.82650592, 0.94031581],\n",
    "                   [0.602314  , 0.48909991],\n",
    "                   [0.79243015, 0.97246033],\n",
    "                   [0.37390621, 0.38079451],\n",
    "                   [0.52138253, 0.70116475],\n",
    "                   [0.07308463, 0.70686879],\n",
    "                   [0.74297229, 0.19681071],\n",
    "                   [0.68506255, 0.0115562 ]]), \n",
    "                   [1,1,1,1,1,1,0,0,0])\n",
    "        \"\"\"\n",
    "        dim = X.shape[1]\n",
    "        self.alpha = np.zeros(dim**2+dim+1)\n",
    "        self.steps = 0\n",
    "        correction_isneeded = True\n",
    "        while (correction_isneeded):\n",
    "            correction_isneeded = False\n",
    "            for row_index in range(len(X)):\n",
    "                ksi = self.make_expanded_vector(X[row_index], dim)\n",
    "                if (np.dot(ksi,self.alpha) >= 0 and target[row_index] == 1):\n",
    "                    correction_isneeded = True\n",
    "                    self.alpha -= ksi\n",
    "                    self.steps += 1\n",
    "                \n",
    "                if (np.dot(ksi,self.alpha) <= 0 and target[row_index] == 0):\n",
    "                    correction_isneeded = True\n",
    "                    self.alpha += ksi\n",
    "                    self.steps += 1 \n",
    "                \n",
    "            self.check_positive_defined_matrix(dim)\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_values: [1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0],\n",
      " prediction: [1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0],\n",
      " accuracy: 0.8125, \n",
      " alpha: [ 2.49577582 -0.75907003 -0.75907003  0.84575901 -0.29769394 -0.13948884\n",
      " -1.        ]\n"
     ]
    }
   ],
   "source": [
    "clasifier = Perceptron()\n",
    "clasifier.fit(Xtrain, Ytrain)\n",
    "prediction = clasifier.predict(Xtest)\n",
    "\n",
    "print ('true_values: {},\\n prediction: {},\\n accuracy: {}, \\n alpha: {}'\\\n",
    "       .format(Ytest, prediction, accuracy_score(Ytest, prediction), clasifier.alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_regions(Xtest, Ytest, clf=clasifier, legend=2)\n",
    "# Adding axes annotations\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('Perceptron on sample of Gaussian distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
